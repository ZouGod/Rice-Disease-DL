{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_PpNo_69JYP"
      },
      "source": [
        "# **Resnet-50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_gC-qFTg9NSF",
        "outputId": "ac241e17-8609-4ef6-ca2d-3a5dbbe2eae1"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install pillow\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch CUDA availability: False\n",
            "Number of CUDA devices: 0\n",
            "Device name: No GPU detected\n",
            "CUDA version: None\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch CUDA availability: {torch.cuda.is_available()}\")\n",
        "print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
        "print(f\"Device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU detected'}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsmJg9gw9uAN"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcIHekpg9Vqw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUg5VFXg_HoN"
      },
      "source": [
        "# **Data Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmeWS8uW-3aW"
      },
      "outputs": [],
      "source": [
        "train_dir = r'D:\\CADT\\CapstoneProjectI\\ml__model\\data\\splited_data\\train'\n",
        "val_dir = r'D:\\CADT\\CapstoneProjectI\\ml__model\\data\\splited_data\\val'\n",
        "test_dir = r'D:\\CADT\\CapstoneProjectI\\ml__model\\data\\splited_data\\test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWZmKWk2_kHe"
      },
      "source": [
        "# **Define image augmentation and preprocessing for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VgOm6G3_rts"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU3HrJBRD1GW"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_dataset = ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset = ImageFolder(val_dir, transform=val_test_transforms)\n",
        "test_dataset = ImageFolder(test_dir, transform=val_test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EwegPNYD3SS"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device and explicitly check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU is available! Using device: {torch.cuda.get_device_name(0)}\")\n",
        "    # Set CUDA_VISIBLE_DEVICES if you want to specify a particular GPU (e.g., GPU 0)\n",
        "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Uncomment and adjust if you have multiple GPUs\n",
        "else:\n",
        "    print(\"GPU not available. Using CPU instead. Training may be slower.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device (check for GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XkeCH1RD62k",
        "outputId": "3e2ee8b2-a25e-42ad-c9ae-a03676880406"
      },
      "outputs": [],
      "source": [
        "# Load and modify ResNet-50\n",
        "model = resnet50(pretrained=True)\n",
        "torch.cuda.empty_cache()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 7)  # Assuming 7 classes as per your previous setup\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVUcfJ_GD_7_",
        "outputId": "f7cdeb1c-a252-4a18-9a1e-20d49a87ab91"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcZs4J1iBKH6"
      },
      "source": [
        "# **Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-QblerCBOIZ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Initialize plot for live updates\n",
        "    plt.ion()\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Optional: Print batch progress\n",
        "            if (i + 1) % (len(train_loader) // 5) == 0:  # Update 5 times per epoch\n",
        "                print(f'Epoch {epoch+1}, Batch {i+1}/{len(train_loader)}')\n",
        "\n",
        "        epoch_train_loss = train_loss / len(train_loader)\n",
        "        epoch_train_acc = 100 * train_correct / train_total\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_accuracies.append(epoch_train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = val_loss / len(val_loader)\n",
        "        epoch_val_acc = 100 * val_correct / val_total\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_accuracies.append(epoch_val_acc)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs} Results:')\n",
        "        print(f'Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.2f}%')\n",
        "        print(f'Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.2f}%')\n",
        "        print('-' * 50)\n",
        "\n",
        "        # Update live plots\n",
        "        ax1.clear()\n",
        "        ax1.plot(train_losses, label='Train Loss')\n",
        "        ax1.plot(val_losses, label='Val Loss')\n",
        "        ax1.set_title('Training vs Validation Loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        ax2.clear()\n",
        "        ax2.plot(train_accuracies, label='Train Accuracy')\n",
        "        ax2.plot(val_accuracies, label='Val Accuracy')\n",
        "        ax2.set_title('Training vs Validation Accuracy')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Accuracy (%)')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        fig.canvas.draw()\n",
        "        fig.canvas.flush_events()\n",
        "\n",
        "    plt.ioff()  # Turn off interactive mode after training\n",
        "    plt.show()\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ucm2WltBltt",
        "outputId": "5634c44c-b386-4671-ff20-7b070395e766"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, val_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLZnWUcRCfpi"
      },
      "outputs": [],
      "source": [
        "# Plot Loss Curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Accuracy Curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Training Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMaoMdhxCrSq"
      },
      "source": [
        "# **Testing Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzf9k7_VCiZR"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names,\n",
        "                yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    # Overall accuracy\n",
        "    accuracy = 100 * sum([1 for p, t in zip(all_preds, all_labels) if p == t]) / len(all_labels)\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRbNqZa_FaMG"
      },
      "outputs": [],
      "source": [
        "# Get class names\n",
        "class_names = train_dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehdFpSbpFb86"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "evaluate_model(model, test_loader, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76s1lE4KCmQO"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/CapstoneProjectI/model/resnet50_10epoch_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLcyjDOOH2Nw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGtXxfKpH2wM"
      },
      "source": [
        "# Check Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDK_nEUwH5Gg",
        "outputId": "4e4ea211-087a-4af4-bbcb-7dced5309453"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to check all datasets and count images\n",
        "def check_all_datasets(base_path):\n",
        "    \"\"\"\n",
        "    Check and count images in train, val, and test datasets.\n",
        "\n",
        "    Args:\n",
        "        base_path (str): Base directory path containing 'train', 'val', and 'test' folders\n",
        "\n",
        "    Returns:\n",
        "        dict: Summary of image counts per dataset and class\n",
        "    \"\"\"\n",
        "    datasets = ['train', 'val', 'test']\n",
        "    summary = {}\n",
        "\n",
        "    for dataset in datasets:\n",
        "        dataset_path = os.path.join(base_path, dataset)\n",
        "        print(f\"\\n=== Checking {dataset.upper()} Dataset ===\")\n",
        "\n",
        "        if not os.path.exists(dataset_path):\n",
        "            print(f\"Error: Path does not exist: {dataset_path}\")\n",
        "            continue\n",
        "\n",
        "        classes = sorted(os.listdir(dataset_path))\n",
        "        print(f\"Found {len(classes)} classes: {classes}\")\n",
        "\n",
        "        class_counts = {}\n",
        "        total_images = 0\n",
        "\n",
        "        for class_name in classes:\n",
        "            class_path = os.path.join(dataset_path, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                print(f\"Warning: {class_path} is not a directory\")\n",
        "                continue\n",
        "\n",
        "            # Count valid image files (supported extensions)\n",
        "            valid_extensions = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
        "            image_files = [f for f in os.listdir(class_path) if f.lower().endswith(valid_extensions)]\n",
        "            num_images = len(image_files)\n",
        "\n",
        "            class_counts[class_name] = num_images\n",
        "            total_images += num_images\n",
        "\n",
        "            print(f\"\\nClass '{class_name}':\")\n",
        "            print(f\"Number of valid images: {num_images}\")\n",
        "            if num_images > 0:\n",
        "                print(f\"Sample files: {image_files[:5]}\")  # Show first 5 files as examples\n",
        "            else:\n",
        "                print(\"Warning: No valid images found in this class folder\")\n",
        "                print(f\"Files present: {os.listdir(class_path)}\")  # Show all files for debugging\n",
        "\n",
        "        summary[dataset] = {\n",
        "            'classes': classes,\n",
        "            'class_counts': class_counts,\n",
        "            'total_images': total_images\n",
        "        }\n",
        "        print(f\"\\nTotal images in {dataset.upper()} dataset: {total_images}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n=== Final Summary ===\")\n",
        "    for dataset in datasets:\n",
        "        print(f\"{dataset.upper()} Dataset:\")\n",
        "        print(f\"Total classes: {len(summary[dataset]['classes'])}\")\n",
        "        print(f\"Total images: {summary[dataset]['total_images']}\")\n",
        "        print(f\"Image count per class: {summary[dataset]['class_counts']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Define the base path and run the check\n",
        "base_path = '/content/drive/MyDrive/CapstoneProjectI/splited_data'\n",
        "dataset_summary = check_all_datasets(base_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
